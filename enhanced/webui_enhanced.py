import json
import os
import sys
import threading
import time
import uuid
from datetime import datetime
from typing import Dict, List, Optional

import warnings
warnings.filterwarnings("ignore", category=FutureWarning)
warnings.filterwarnings("ignore", category=UserWarning)

current_dir = os.path.dirname(os.path.abspath(__file__))
sys.path.append(current_dir)
sys.path.append(os.path.join(current_dir, "indextts"))

import argparse
import pandas as pd
import gradio as gr
from fastapi import FastAPI, HTTPException
from fastapi.responses import FileResponse
from pydantic import BaseModel

from indextts.infer import IndexTTS
from indextts.voice_manager import VoiceManager
from tools.i18n.i18n import I18nAuto
import traceback

# APIè¯·æ±‚æ¨¡å‹
class TTSRequest(BaseModel):
    text: str
    voice_name: str
    infer_mode: str = "æ™®é€šæ¨ç†"
    max_text_tokens_per_sentence: int = 120
    sentences_bucket_max_size: int = 4
    do_sample: bool = True
    top_p: float = 0.8
    top_k: int = 30
    temperature: float = 1.0
    length_penalty: float = 0.0
    num_beams: int = 3
    repetition_penalty: float = 10.0
    max_mel_tokens: int = 600
    filename: Optional[str] = None  # è‡ªå®šä¹‰æ–‡ä»¶åï¼ˆä¸åŒ…å«æ‰©å±•åï¼‰

class TTSResponse(BaseModel):
    success: bool
    message: str
    audio_url: Optional[str] = None
    task_id: Optional[str] = None

# è§£æå‘½ä»¤è¡Œå‚æ•°
parser = argparse.ArgumentParser(description="IndexTTS Enhanced WebUI with API")
parser.add_argument("--verbose", action="store_true", default=False, help="Enable verbose mode")
parser.add_argument("--port", type=int, default=7860, help="Port to run the web UI on")
parser.add_argument("--host", type=str, default="0.0.0.0", help="Host to run the web UI on")
parser.add_argument("--model_dir", type=str, default="checkpoints", help="Model checkpoints directory")
parser.add_argument("--enable_api", action="store_true", default=True, help="Enable API endpoints")
cmd_args = parser.parse_args()

# æ£€æŸ¥æ¨¡å‹æ–‡ä»¶
if not os.path.exists(cmd_args.model_dir):
    print(f"Model directory {cmd_args.model_dir} does not exist. Please download the model first.")
    sys.exit(1)

for file in [
    "bigvgan_generator.pth",
    "bpe.model", 
    "gpt.pth",
    "config.yaml",
]:
    file_path = os.path.join(cmd_args.model_dir, file)
    if not os.path.exists(file_path):
        print(f"Required file {file_path} does not exist. Please download it.")
        sys.exit(1)

# åˆå§‹åŒ–ç»„ä»¶
i18n = I18nAuto(language="zh_CN")
tts = IndexTTS(model_dir=cmd_args.model_dir, cfg_path=os.path.join(cmd_args.model_dir, "config.yaml"))
voice_manager = VoiceManager()

# åˆ›å»ºå¿…è¦ç›®å½•
os.makedirs("outputs/tasks", exist_ok=True)
os.makedirs("outputs/api", exist_ok=True)
os.makedirs("prompts", exist_ok=True)

# åŠ è½½ç¤ºä¾‹
with open("tests/cases.jsonl", "r", encoding="utf-8") as f:
    example_cases = []
    for line in f:
        line = line.strip()
        if not line:
            continue
        example = json.loads(line)
        example_cases.append([os.path.join("tests", example.get("prompt_audio", "sample_prompt.wav")),
                              example.get("text"), ["æ™®é€šæ¨ç†", "æ‰¹æ¬¡æ¨ç†"][example.get("infer_mode", 0)]])

def generate_tts_internal(prompt_audio_path, text, infer_mode, max_text_tokens_per_sentence=120, 
                         sentences_bucket_max_size=4, custom_filename=None, **generation_kwargs):
    """å†…éƒ¨TTSç”Ÿæˆå‡½æ•°"""
    if not prompt_audio_path:
        return None, "è¯·æä¾›å‚è€ƒéŸ³é¢‘"
    
    if not text or not text.strip():
        return None, "è¯·è¾“å…¥æ–‡æœ¬å†…å®¹"
    
    # ç”Ÿæˆè¾“å‡ºè·¯å¾„
    task_id = str(uuid.uuid4())
    
    # æ”¯æŒè‡ªå®šä¹‰æ–‡ä»¶å
    if custom_filename:
        # æ¸…ç†æ–‡ä»¶åï¼Œç§»é™¤éæ³•å­—ç¬¦
        import re
        safe_filename = re.sub(r'[<>:"/\\|?*]', '_', custom_filename)
        filename = f"{safe_filename}.wav"
    else:
        filename = f"tts_{task_id}.wav"
    
    output_path = os.path.join("outputs", "api", filename)
    
    # å¦‚æœæ–‡ä»¶å·²å­˜åœ¨ï¼Œæ·»åŠ æ—¶é—´æˆ³
    if os.path.exists(output_path):
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        name_part = filename.replace('.wav', '')
        filename = f"{name_part}_{timestamp}.wav"
        output_path = os.path.join("outputs", "api", filename)
    
    try:
        if infer_mode == "æ™®é€šæ¨ç†":
            result = tts.infer(prompt_audio_path, text, output_path, verbose=cmd_args.verbose,
                              max_text_tokens_per_sentence=int(max_text_tokens_per_sentence),
                              **generation_kwargs)
        else:
            # æ‰¹æ¬¡æ¨ç†
            result = tts.infer_fast(prompt_audio_path, text, output_path, verbose=cmd_args.verbose,
                                   max_text_tokens_per_sentence=int(max_text_tokens_per_sentence),
                                   sentences_bucket_max_size=int(sentences_bucket_max_size),
                                   **generation_kwargs)
        
        if result and os.path.exists(output_path):
            return output_path, "ç”ŸæˆæˆåŠŸ"
        else:
            return None, "ç”Ÿæˆå¤±è´¥"
            
    except Exception as e:
        tb = traceback.format_exc()
        return None, f"ç”Ÿæˆå¤±è´¥: {str(e)}\n{tb}"

def gen_single(prompt, text, infer_mode, max_text_tokens_per_sentence=120, sentences_bucket_max_size=4,
               *args, progress=gr.Progress()):
    """å•ä¸ªéŸ³é¢‘ç”Ÿæˆ"""
    if not prompt:
        return gr.update(value=None), "è¯·å…ˆä¸Šä¼ å‚è€ƒéŸ³é¢‘"
    
    output_path = os.path.join("outputs", f"spk_{int(time.time())}.wav")
    tts.gr_progress = progress
    
    do_sample, top_p, top_k, temperature, \
        length_penalty, num_beams, repetition_penalty, max_mel_tokens = args
    
    kwargs = {
        "do_sample": bool(do_sample),
        "top_p": float(top_p),
        "top_k": int(top_k) if int(top_k) > 0 else None,
        "temperature": float(temperature),
        "length_penalty": float(length_penalty),
        "num_beams": num_beams,
        "repetition_penalty": float(repetition_penalty),
        "max_mel_tokens": int(max_mel_tokens),
    }
    
    try:
        if infer_mode == "æ™®é€šæ¨ç†":
            output = tts.infer(prompt, text, output_path, verbose=cmd_args.verbose,
                              max_text_tokens_per_sentence=int(max_text_tokens_per_sentence),
                              **kwargs)
        else:
            output = tts.infer_fast(prompt, text, output_path, verbose=cmd_args.verbose,
                                   max_text_tokens_per_sentence=int(max_text_tokens_per_sentence),
                                   sentences_bucket_max_size=int(sentences_bucket_max_size),
                                   **kwargs)
        return gr.update(value=output, visible=True), "ç”ŸæˆæˆåŠŸ"
    except Exception as e:
        return gr.update(value=None), f"ç”Ÿæˆå¤±è´¥: {str(e)}"

def save_voice_action(prompt_audio, voice_name, voice_description):
    """ä¿å­˜éŸ³è‰²åŠ¨ä½œ"""
    if not prompt_audio:
        return "è¯·å…ˆä¸Šä¼ éŸ³é¢‘æ–‡ä»¶", gr.update(), gr.update()
    
    if not voice_name or not voice_name.strip():
        return "è¯·è¾“å…¥éŸ³è‰²åç§°", gr.update(), gr.update()
    
    voice_name = voice_name.strip()
    result = voice_manager.save_voice(prompt_audio, voice_name, voice_description or "")
    
    if result["success"]:
        # æ›´æ–°éŸ³è‰²åˆ—è¡¨
        voices_list = get_voices_list()
        new_value = voices_list[0] if voices_list else None
        return result["message"], gr.update(choices=voices_list, value=new_value), gr.update(choices=voices_list, value=new_value)
    else:
        return result["message"], gr.update(), gr.update()

def delete_voice_action(voice_name):
    """åˆ é™¤éŸ³è‰²åŠ¨ä½œ"""
    if not voice_name or voice_name is None:
        return "è¯·é€‰æ‹©è¦åˆ é™¤çš„éŸ³è‰²", gr.update(), gr.update()
    
    result = voice_manager.delete_voice(voice_name)
    
    if result["success"]:
        voices_list = get_voices_list()
        new_value = voices_list[0] if voices_list else None
        return result["message"], gr.update(choices=voices_list, value=new_value), gr.update(choices=voices_list, value=new_value)
    else:
        return result["message"], gr.update(), gr.update()

def get_voices_list():
    """è·å–éŸ³è‰²åˆ—è¡¨"""
    voices = voice_manager.list_voices()
    return [voice["name"] for voice in voices]

def load_voice_action(voice_name):
    """åŠ è½½é€‰ä¸­çš„éŸ³è‰²"""
    if not voice_name or voice_name is None:
        return gr.update(), "è¯·é€‰æ‹©éŸ³è‰²"
    
    audio_path = voice_manager.get_voice_audio_path(voice_name)
    if audio_path:
        return gr.update(value=audio_path), f"å·²åŠ è½½éŸ³è‰²: {voice_name}"
    else:
        return gr.update(), f"éŸ³è‰²æ–‡ä»¶ä¸å­˜åœ¨: {voice_name}"

def get_voices_table():
    """è·å–éŸ³è‰²è¡¨æ ¼æ•°æ®"""
    voices = voice_manager.list_voices()
    if not voices:
        return []
    
    data = []
    for voice in voices:
        data.append([
            voice["name"],
            voice.get("description", ""),
            f"{voice.get('duration', 0):.1f}s",
            datetime.fromtimestamp(voice.get("created_time", 0)).strftime("%Y-%m-%d %H:%M:%S"),
            f"{voice.get('file_size', 0) / 1024:.1f}KB"
        ])
    return data

def update_prompt_audio():
    """æ›´æ–°éŸ³é¢‘ä¸Šä¼ çŠ¶æ€"""
    return gr.update(interactive=True)

def on_input_text_change(text, max_tokens_per_sentence):
    """æ–‡æœ¬å˜åŒ–æ—¶é¢„è§ˆåˆ†å¥"""
    if text and len(text) > 0:
        text_tokens_list = tts.tokenizer.tokenize(text)
        sentences = tts.tokenizer.split_sentences(text_tokens_list, max_tokens_per_sentence=int(max_tokens_per_sentence))
        data = []
        for i, s in enumerate(sentences):
            sentence_str = ''.join(s)
            tokens_count = len(s)
            data.append([i, sentence_str, tokens_count])
        
        return gr.update(value=data, visible=True, type="array")
    else:
        return gr.update(value=[])

# åˆ›å»ºGradioç•Œé¢
with gr.Blocks(title="IndexTTS Enhanced Demo") as demo:
    mutex = threading.Lock()
    
    gr.HTML('''
    <h2><center>IndexTTS Enhanced: éŸ³è‰²ä¿å­˜åŠŸèƒ½ + APIæ¥å£</h2>
    <h2><center>(Enhanced IndexTTS with Voice Management & API)</h2>
    <p align="center">
    <a href='https://arxiv.org/abs/2502.05512'><img src='https://img.shields.io/badge/ArXiv-2502.05512-red'></a>
    </p>
    ''')
    
    with gr.Tab("ğŸ¤ éŸ³é¢‘ç”Ÿæˆ"):
        with gr.Row():
            with gr.Column(scale=1):
                prompt_audio = gr.Audio(label="å‚è€ƒéŸ³é¢‘", sources=["upload", "microphone"], type="filepath")
                
                # éŸ³è‰²ä¿å­˜åŠŸèƒ½
                with gr.Group():
                    gr.Markdown("### ğŸ’¾ ä¿å­˜éŸ³è‰²")
                    voice_name_input = gr.Textbox(label="éŸ³è‰²åç§°", placeholder="ç»™è¿™ä¸ªéŸ³è‰²èµ·ä¸ªåå­—...")
                    voice_description_input = gr.Textbox(label="éŸ³è‰²æè¿°", placeholder="æè¿°è¿™ä¸ªéŸ³è‰²çš„ç‰¹ç‚¹ï¼ˆå¯é€‰ï¼‰")
                    save_voice_btn = gr.Button("ä¿å­˜éŸ³è‰²", variant="secondary")
                
                # åŠ è½½å·²ä¿å­˜éŸ³è‰²
                with gr.Group():
                    gr.Markdown("### ğŸ“‚ åŠ è½½éŸ³è‰²")
                    voices_choices = get_voices_list()
                    saved_voices_dropdown = gr.Dropdown(
                        label="é€‰æ‹©éŸ³è‰²", 
                        choices=voices_choices,
                        value=voices_choices[0] if voices_choices else None,
                        interactive=True
                    )
                    load_voice_btn = gr.Button("åŠ è½½éŸ³è‰²", variant="secondary")
                
            with gr.Column(scale=2):
                input_text_single = gr.TextArea(
                    label="æ–‡æœ¬", 
                    placeholder="è¯·è¾“å…¥ç›®æ ‡æ–‡æœ¬", 
                    info=f"å½“å‰æ¨¡å‹ç‰ˆæœ¬{tts.model_version or '1.0'}"
                )
                infer_mode = gr.Radio(
                    choices=["æ™®é€šæ¨ç†", "æ‰¹æ¬¡æ¨ç†"], 
                    label="æ¨ç†æ¨¡å¼",
                    info="æ‰¹æ¬¡æ¨ç†ï¼šæ›´é€‚åˆé•¿å¥ï¼Œæ€§èƒ½ç¿»å€",
                    value="æ™®é€šæ¨ç†"
                )
                gen_button = gr.Button("ğŸµ ç”Ÿæˆè¯­éŸ³", variant="primary")
                
                status_text = gr.Textbox(label="çŠ¶æ€", interactive=False)
                output_audio = gr.Audio(label="ç”Ÿæˆç»“æœ", visible=True)
        
        # é«˜çº§å‚æ•°è®¾ç½®
        with gr.Accordion("âš™ï¸ é«˜çº§ç”Ÿæˆå‚æ•°è®¾ç½®", open=False):
            with gr.Row():
                with gr.Column(scale=1):
                    gr.Markdown("**GPT2 é‡‡æ ·è®¾ç½®**")
                    with gr.Row():
                        do_sample = gr.Checkbox(label="do_sample", value=True, info="æ˜¯å¦è¿›è¡Œé‡‡æ ·")
                        temperature = gr.Slider(label="temperature", minimum=0.1, maximum=2.0, value=1.0, step=0.1)
                    with gr.Row():
                        top_p = gr.Slider(label="top_p", minimum=0.0, maximum=1.0, value=0.8, step=0.01)
                        top_k = gr.Slider(label="top_k", minimum=0, maximum=100, value=30, step=1)
                        num_beams = gr.Slider(label="num_beams", value=3, minimum=1, maximum=10, step=1)
                    with gr.Row():
                        repetition_penalty = gr.Number(label="repetition_penalty", value=10.0, minimum=0.1, maximum=20.0, step=0.1)
                        length_penalty = gr.Number(label="length_penalty", value=0.0, minimum=-2.0, maximum=2.0, step=0.1)
                    max_mel_tokens = gr.Slider(
                        label="max_mel_tokens", 
                        value=600, 
                        minimum=50, 
                        maximum=tts.cfg.gpt.max_mel_tokens, 
                        step=10, 
                        info="ç”ŸæˆTokenæœ€å¤§æ•°é‡"
                    )
                
                with gr.Column(scale=2):
                    gr.Markdown("**åˆ†å¥è®¾ç½®**")
                    with gr.Row():
                        max_text_tokens_per_sentence = gr.Slider(
                            label="åˆ†å¥æœ€å¤§Tokenæ•°", 
                            value=120, 
                            minimum=20, 
                            maximum=tts.cfg.gpt.max_text_tokens, 
                            step=2,
                            info="å»ºè®®80~200ä¹‹é—´"
                        )
                        sentences_bucket_max_size = gr.Slider(
                            label="åˆ†å¥åˆ†æ¡¶çš„æœ€å¤§å®¹é‡ï¼ˆæ‰¹æ¬¡æ¨ç†ç”Ÿæ•ˆï¼‰", 
                            value=4, 
                            minimum=1, 
                            maximum=16, 
                            step=1,
                            info="å»ºè®®2-8ä¹‹é—´"
                        )
                    
                    with gr.Accordion("é¢„è§ˆåˆ†å¥ç»“æœ", open=True):
                        sentences_preview = gr.Dataframe(
                            headers=["åºå·", "åˆ†å¥å†…å®¹", "Tokenæ•°"],
                            wrap=True
                        )
        
        advanced_params = [
            do_sample, top_p, top_k, temperature,
            length_penalty, num_beams, repetition_penalty, max_mel_tokens
        ]
        
        # ç¤ºä¾‹
        if len(example_cases) > 0:
            gr.Examples(
                examples=example_cases,
                inputs=[prompt_audio, input_text_single, infer_mode]
            )
    
    with gr.Tab("ğŸ“š éŸ³è‰²ç®¡ç†"):
        with gr.Row():
            with gr.Column():
                gr.Markdown("### å·²ä¿å­˜çš„éŸ³è‰²")
                voices_table = gr.Dataframe(
                    headers=["éŸ³è‰²åç§°", "æè¿°", "æ—¶é•¿", "åˆ›å»ºæ—¶é—´", "æ–‡ä»¶å¤§å°"],
                    value=get_voices_table(),
                    interactive=False
                )
                refresh_btn = gr.Button("ğŸ”„ åˆ·æ–°åˆ—è¡¨")
                
            with gr.Column():
                gr.Markdown("### éŸ³è‰²æ“ä½œ")
                delete_voices_choices = get_voices_list()
                delete_voice_dropdown = gr.Dropdown(
                    label="é€‰æ‹©è¦åˆ é™¤çš„éŸ³è‰²",
                    choices=delete_voices_choices,
                    value=delete_voices_choices[0] if delete_voices_choices else None
                )
                delete_voice_btn = gr.Button("ğŸ—‘ï¸ åˆ é™¤éŸ³è‰²", variant="stop")
                delete_status = gr.Textbox(label="æ“ä½œçŠ¶æ€", interactive=False)
    
    with gr.Tab("ğŸ”Œ APIè¯´æ˜"):
        gr.Markdown("""
        ### APIæ¥å£ä½¿ç”¨è¯´æ˜
        
        æœ¬ç³»ç»Ÿæä¾›RESTful APIæ¥å£ï¼Œå¯ä»¥é€šè¿‡HTTPè¯·æ±‚è°ƒç”¨TTSåŠŸèƒ½ï¼Œé€‚åˆé›†æˆåˆ°difyå·¥ä½œæµä¸­ã€‚
        
        #### 1. ç”Ÿæˆè¯­éŸ³ API
        **æ”¯æŒä¸¤ç§æ¥å£å’Œä¸¤ç§å“åº”æ ¼å¼**
        
        **æ¥å£1: POST /api/tts (è¿”å›JSONå“åº”)**
        - è¿”å›åŒ…å«éŸ³é¢‘URLçš„JSONå“åº”
        
        **æ¥å£2: POST /api/tts/file (ç›´æ¥è¿”å›éŸ³é¢‘æ–‡ä»¶)**
        - ç›´æ¥è¿”å›éŸ³é¢‘æ–‡ä»¶ï¼Œæ— éœ€äºŒæ¬¡è¯·æ±‚
        
        **å‚æ•°ä¼ é€’æ–¹å¼:**
        
        **æ–¹å¼1: JSON Body (æ¨è)**
        ```json
        {
            "text": "è¦è½¬æ¢çš„æ–‡æœ¬",
            "voice_name": "éŸ³è‰²åç§°",
            "infer_mode": "æ™®é€šæ¨ç†",
            "max_text_tokens_per_sentence": 120,
            "temperature": 1.0,
            "top_p": 0.8,
            "top_k": 30,
            "return_file": false
        }
        ```
        
        **æ–¹å¼2: URLå‚æ•°**
        ```
        POST /api/tts?text=è¦è½¬æ¢çš„æ–‡æœ¬&voice_name=éŸ³è‰²åç§°&return_file=true
        ```
        
        **å“åº”:**
        - `/api/tts`: JSONæ ¼å¼ `{"success": true, "audio_url": "/api/audio/xxx.wav"}`
        - `/api/tts/file`: ç›´æ¥è¿”å›wavéŸ³é¢‘æ–‡ä»¶
        - æˆ–åœ¨ä»»æ„æ¥å£ä¸­æ·»åŠ  `return_file=true` å‚æ•°ç›´æ¥è¿”å›éŸ³é¢‘æ–‡ä»¶
        
        #### 2. è·å–éŸ³è‰²åˆ—è¡¨ API
        - **URL**: `GET /api/voices`
        - **å“åº”**: è¿”å›æ‰€æœ‰å¯ç”¨éŸ³è‰²åˆ—è¡¨
        
        #### 3. ä¸‹è½½éŸ³é¢‘æ–‡ä»¶
        - **URL**: `GET /api/audio/{filename}`
        - **å“åº”**: è¿”å›éŸ³é¢‘æ–‡ä»¶
        
        #### Difyå·¥ä½œæµé›†æˆç¤ºä¾‹
        åœ¨difyå·¥ä½œæµä¸­ï¼Œæ‚¨å¯ä»¥ä½¿ç”¨HTTPèŠ‚ç‚¹è°ƒç”¨APIï¼š
        1. è®¾ç½®è¯·æ±‚URLä¸º: `http://your-server:7860/api/tts`
        2. è®¾ç½®è¯·æ±‚æ–¹æ³•ä¸º: `POST`
        3. è®¾ç½®Content-Typeä¸º: `application/json`
        4. åœ¨è¯·æ±‚ä½“ä¸­ä¼ å…¥æ–‡æœ¬å’ŒéŸ³è‰²åç§°
        5. ä»å“åº”ä¸­è·å–audio_urlè¿›è¡Œåç»­å¤„ç†
        """)
    
    # äº‹ä»¶ç»‘å®š
    prompt_audio.upload(update_prompt_audio, outputs=[gen_button])
    
    # ç”Ÿæˆè¯­éŸ³
    gen_button.click(
        gen_single,
        inputs=[prompt_audio, input_text_single, infer_mode,
                max_text_tokens_per_sentence, sentences_bucket_max_size] + advanced_params,
        outputs=[output_audio, status_text]
    )
    
    # ä¿å­˜éŸ³è‰²
    save_voice_btn.click(
        save_voice_action,
        inputs=[prompt_audio, voice_name_input, voice_description_input],
        outputs=[status_text, saved_voices_dropdown, delete_voice_dropdown]
    )
    
    # åŠ è½½éŸ³è‰²
    load_voice_btn.click(
        load_voice_action,
        inputs=[saved_voices_dropdown],
        outputs=[prompt_audio, status_text]
    )
    
    # åˆ é™¤éŸ³è‰²
    delete_voice_btn.click(
        delete_voice_action,
        inputs=[delete_voice_dropdown],
        outputs=[delete_status, saved_voices_dropdown, delete_voice_dropdown]
    )
    
    # åˆ·æ–°éŸ³è‰²åˆ—è¡¨
    def refresh_voices():
        voices_list = get_voices_list()
        table_data = get_voices_table()
        new_value = voices_list[0] if voices_list else None
        return table_data, gr.update(choices=voices_list, value=new_value), gr.update(choices=voices_list, value=new_value)
    
    refresh_btn.click(
        refresh_voices,
        outputs=[voices_table, saved_voices_dropdown, delete_voice_dropdown]
    )
    
    # æ–‡æœ¬å˜åŒ–é¢„è§ˆ
    input_text_single.change(
        on_input_text_change,
        inputs=[input_text_single, max_text_tokens_per_sentence],
        outputs=[sentences_preview]
    )
    max_text_tokens_per_sentence.change(
        on_input_text_change,
        inputs=[input_text_single, max_text_tokens_per_sentence],
        outputs=[sentences_preview]
    )

# åˆ›å»ºFastAPIåº”ç”¨
if cmd_args.enable_api:
    from fastapi import Request
    app = FastAPI(title="IndexTTS API", description="IndexTTS API for dify workflow integration")

    async def _process_tts_request(request: TTSRequest):
        """å¤„ç†TTSè¯·æ±‚çš„å…±ç”¨å‡½æ•°"""
        try:
            # æ£€æŸ¥éŸ³è‰²æ˜¯å¦å­˜åœ¨
            audio_path = voice_manager.get_voice_audio_path(request.voice_name)
            if not audio_path:
                raise HTTPException(status_code=400, detail=f"éŸ³è‰² '{request.voice_name}' ä¸å­˜åœ¨")
            
            # å‡†å¤‡ç”Ÿæˆå‚æ•°
            generation_kwargs = {
                "do_sample": request.do_sample,
                "top_p": request.top_p,
                "top_k": request.top_k,
                "temperature": request.temperature,
                "length_penalty": request.length_penalty,
                "num_beams": request.num_beams,
                "repetition_penalty": request.repetition_penalty,
                "max_mel_tokens": request.max_mel_tokens,
            }
            
            # ç”Ÿæˆè¯­éŸ³
            output_path, message = generate_tts_internal(
                audio_path,
                request.text,
                request.infer_mode,
                request.max_text_tokens_per_sentence,
                request.sentences_bucket_max_size,
                custom_filename=request.filename,
                **generation_kwargs
            )
            
            if output_path:
                # ç”ŸæˆéŸ³é¢‘URL
                filename = os.path.basename(output_path)
                audio_url = f"/api/audio/{filename}"
                
                # æ­£ç¡®è®¡ç®—task_id
                if filename.startswith("tts_") and filename.endswith(".wav"):
                    task_id = filename.replace("tts_", "").replace(".wav", "")
                else:
                    task_id = filename.replace(".wav", "")
                
                return TTSResponse(
                    success=True,
                    message=message,
                    audio_url=audio_url,
                    task_id=task_id
                )
            else:
                return TTSResponse(success=False, message=message)
                
        except Exception as e:
            raise HTTPException(status_code=500, detail=str(e))

    @app.post("/api/tts", response_model=TTSResponse)
    async def api_tts(request: Request):
        """TTS APIæ¥å£ - è¿”å›JSONå“åº”ï¼ˆåŒ…å«éŸ³é¢‘URLï¼‰"""
        return await _handle_tts_request(request, return_file=False)
    
    @app.post("/api/tts/file")
    async def api_tts_file(request: Request):
        """TTS APIæ¥å£ - ç›´æ¥è¿”å›éŸ³é¢‘æ–‡ä»¶"""
        return await _handle_tts_request(request, return_file=True)
    
    async def _handle_tts_request(request: Request, return_file: bool = False):
        """å¤„ç†TTSè¯·æ±‚çš„ç»Ÿä¸€å‡½æ•°"""
        try:
            content_type = request.headers.get("content-type", "")
            
            # æ£€æŸ¥æ˜¯å¦æœ‰return_fileå‚æ•°
            params = dict(request.query_params)
            if params.get("return_file", "false").lower() == "true":
                return_file = True
            
            if "application/json" in content_type:
                # JSON body
                body = await request.json()
                return_file = body.pop("return_file", return_file)  # ä»bodyä¸­æå–return_fileå‚æ•°
                tts_request = TTSRequest(**body)
            else:
                # URLå‚æ•° (é€‚ç”¨äºGETé£æ ¼çš„POSTè¯·æ±‚)
                if not params.get("text") or not params.get("voice_name"):
                    raise HTTPException(status_code=400, detail="ç¼ºå°‘å¿…éœ€å‚æ•°: text å’Œ voice_name")
                
                # è½¬æ¢å‚æ•°ç±»å‹
                tts_request = TTSRequest(
                    text=params.get("text"),
                    voice_name=params.get("voice_name"),
                    infer_mode=params.get("infer_mode", "æ™®é€šæ¨ç†"),
                    max_text_tokens_per_sentence=int(params.get("max_text_tokens_per_sentence", 120)),
                    sentences_bucket_max_size=int(params.get("sentences_bucket_max_size", 4)),
                    do_sample=params.get("do_sample", "true").lower() == "true",
                    top_p=float(params.get("top_p", 0.8)),
                    top_k=int(params.get("top_k", 30)),
                    temperature=float(params.get("temperature", 1.0)),
                    length_penalty=float(params.get("length_penalty", 0.0)),
                    num_beams=int(params.get("num_beams", 3)),
                    repetition_penalty=float(params.get("repetition_penalty", 10.0)),
                    max_mel_tokens=int(params.get("max_mel_tokens", 600)),
                    filename=params.get("filename")
                )
            
            # å¤„ç†TTSè¯·æ±‚
            result = await _process_tts_request(tts_request)
            
            if return_file and result.success and result.audio_url:
                # ç›´æ¥è¿”å›éŸ³é¢‘æ–‡ä»¶
                filename = result.audio_url.split("/")[-1]
                file_path = os.path.join("outputs", "api", filename)
                if os.path.exists(file_path):
                    return FileResponse(
                        file_path, 
                        media_type="audio/wav", 
                        filename=f"tts_{tts_request.voice_name}_{result.task_id}.wav"
                    )
                else:
                    raise HTTPException(status_code=404, detail="éŸ³é¢‘æ–‡ä»¶æœªæ‰¾åˆ°")
            else:
                # è¿”å›JSONå“åº”
                return result
            
        except ValueError as e:
            tb = traceback.format_exc()
            return {"success": False, "message": f"å‚æ•°æ ¼å¼é”™è¯¯: {str(e)}\n{tb}"}
        except Exception as e:
            tb = traceback.format_exc()
            return {"success": False, "message": f"ç”Ÿæˆå¤±è´¥: {str(e)}\n{tb}"}

    @app.get("/api/voices")
    async def api_get_voices():
        """è·å–éŸ³è‰²åˆ—è¡¨API"""
        try:
            voices = voice_manager.list_voices()
            return {"success": True, "voices": voices}
        except Exception as e:
            raise HTTPException(status_code=500, detail=str(e))

    @app.get("/api/audio/{filename}")
    async def api_get_audio(filename: str):
        """è·å–éŸ³é¢‘æ–‡ä»¶API"""
        file_path = os.path.join("outputs", "api", filename)
        if os.path.exists(file_path):
            return FileResponse(file_path, media_type="audio/wav", filename=filename)
        else:
            raise HTTPException(status_code=404, detail="éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨")

    # å°†FastAPIåº”ç”¨æŒ‚è½½åˆ°Gradio
    demo = gr.mount_gradio_app(app, demo, path="")

if __name__ == "__main__":
    if cmd_args.enable_api:
        print(f"ğŸš€ å¯åŠ¨IndexTTS Enhanced WebUI + APIæœåŠ¡")
        print(f"ğŸŒ Webç•Œé¢: http://{cmd_args.host}:{cmd_args.port}")
        print(f"ğŸ“¡ APIæ–‡æ¡£: http://{cmd_args.host}:{cmd_args.port}/docs")
        print(f"ğŸµ TTS API: http://{cmd_args.host}:{cmd_args.port}/api/tts")
        print(f"ğŸ“š éŸ³è‰²åˆ—è¡¨: http://{cmd_args.host}:{cmd_args.port}/api/voices")
        
        import uvicorn
        uvicorn.run(app, host=cmd_args.host, port=cmd_args.port)
    else:
        print(f"ğŸš€ å¯åŠ¨IndexTTS Enhanced WebUI (ä»…Webç•Œé¢)")
        print(f"ğŸŒ Webç•Œé¢: http://{cmd_args.host}:{cmd_args.port}")
        demo.queue(20)
        demo.launch(server_name=cmd_args.host, server_port=cmd_args.port) 